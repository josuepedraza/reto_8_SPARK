{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840abb5d-6071-4805-92df-c91345576a7b",
   "metadata": {},
   "source": [
    "## 1. Ingesta (Capa Bronce)\n",
    "# Convertimos CSV crudo a formato Delta Lake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a21e6160-7b0d-4a83-a363-df067cc320ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date\n",
    "from delta import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21928a5-ddb5-4cee-aed2-d98b5569cd8c",
   "metadata": {},
   "source": [
    "# URL del Master (definida en docker-compose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c60ab7-7304-4155-b4f4-d3388d6407af",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_url = \"spark://spark-master:7077\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f60a15-de7d-4904-a38b-c8d630c0868c",
   "metadata": {},
   "source": [
    "# Configuración: Añadimos Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7b1339-38d6-4a62-99f3-df1c0570749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-3c21cb56-977b-469d-b6a4-db4462d4e176;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.0.0 in central\n",
      "\tfound io.delta#delta-storage;3.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 136ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-3c21cb56-977b-469d-b6a4-db4462d4e176\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n",
      "26/02/02 00:37:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "builder = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Lab_SECOP_Bronze\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.executor.memory\", \"1g\")\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379b3a72-846d-4de8-ab94-9fd44af52f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo CSV crudo...\n",
      "Columnas originales:\n",
      "['Entidad', 'Nit Entidad', 'Departamento', 'Ciudad', 'Estado', 'Descripcion del Proceso', 'Tipo de Contrato', 'Modalidad de Contratacion', 'Justificacion Modalidad de Contratacion', 'Fecha de Firma', 'Fecha de Inicio del Contrato', 'Fecha de Fin del Contrato', 'Precio Base', 'Valor Total', 'Valor Pagado']\n",
      "\n",
      "Columnas limpias:\n",
      "['entidad', 'nit_entidad', 'departamento', 'ciudad', 'estado', 'descripcion_del_proceso', 'tipo_de_contrato', 'modalidad_de_contratacion', 'justificacion_modalidad_de_contratacion', 'fecha_de_firma', 'fecha_de_inicio_del_contrato', 'fecha_de_fin_del_contrato', 'precio_base', 'valor_total', 'valor_pagado']\n",
      "Escribiendo en capa Bronce (Delta)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/02 00:46:12 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OK - filas: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Leyendo CSV crudo...\")\n",
    "\n",
    "df_raw = (spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"file:/app/data/SECOP_II_Contratos_Electronicos.csv\")\n",
    ")\n",
    "\n",
    "import re\n",
    "\n",
    "def limpiar_nombre_columna(c: str) -> str:\n",
    "    c = c.strip()\n",
    "    # reemplaza cualquier caracter inválido para Delta por \"_\"\n",
    "    c = re.sub(r\"[ ,;{}\\(\\)\\n\\t=]+\", \"_\", c)\n",
    "    # evita dobles \"__\"\n",
    "    c = re.sub(r\"_+\", \"_\", c)\n",
    "    # evita \"_\" al inicio/fin\n",
    "    c = c.strip(\"_\")\n",
    "    return c.lower()\n",
    "\n",
    "# ver columnas originales\n",
    "print(\"Columnas originales:\")\n",
    "print(df_raw.columns)\n",
    "\n",
    "# renombrar\n",
    "df_bronze = df_raw\n",
    "for c in df_raw.columns:\n",
    "    df_bronze = df_bronze.withColumnRenamed(c, limpiar_nombre_columna(c))\n",
    "\n",
    "print(\"\\nColumnas limpias:\")\n",
    "print(df_bronze.columns)\n",
    "\n",
    "\n",
    "print(\"Escribiendo en capa Bronce (Delta)...\")\n",
    "output_path = \"file:/app/data/lakehouse/bronze/secop\"\n",
    "\n",
    "(df_bronze.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(output_path)\n",
    ")\n",
    "\n",
    "print(\"✅ OK - filas:\", df_bronze.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "105a3054-1d00-474f-ad5e-b03df04ffdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existe _delta_log?: True\n",
      "Archivos: ['.part-00000-355dc564-279d-4fde-a7c9-1f342d0c8c84-c000.snappy.parquet.crc', 'part-00000-355dc564-279d-4fde-a7c9-1f342d0c8c84-c000.snappy.parquet', '_delta_log']\n"
     ]
    }
   ],
   "source": [
    "print(\"Existe _delta_log?:\", os.path.exists(\"/app/data/lakehouse/bronze/secop/_delta_log\"))\n",
    "print(\"Archivos:\", os.listdir(\"/app/data/lakehouse/bronze/secop\")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39baa620-531e-41a1-b88a-69718ba217a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas Bronze: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+------------+------+------+-----------------------+----------------+-------------------------+---------------------------------------+--------------+----------------------------+-------------------------+-----------+-----------+------------+\n",
      "|entidad       |nit_entidad|departamento|ciudad|estado|descripcion_del_proceso|tipo_de_contrato|modalidad_de_contratacion|justificacion_modalidad_de_contratacion|fecha_de_firma|fecha_de_inicio_del_contrato|fecha_de_fin_del_contrato|precio_base|valor_total|valor_pagado|\n",
      "+--------------+-----------+------------+------+------+-----------------------+----------------+-------------------------+---------------------------------------+--------------+----------------------------+-------------------------+-----------+-----------+------------+\n",
      "|ALCALDIA 90   |NULL       |BOLIVAR     |NULL  |NULL  |NULL                   |NULL            |NULL                     |NULL                                   |2023-02-28    |NULL                        |NULL                     |3582652    |NULL       |NULL        |\n",
      "|ALCALDIA 78   |NULL       |CUNDINAMARCA|NULL  |NULL  |NULL                   |NULL            |NULL                     |NULL                                   |2023-05-09    |NULL                        |NULL                     |2745675528 |NULL       |NULL        |\n",
      "|HOSPITAL 23   |NULL       |ATLANTICO   |NULL  |NULL  |NULL                   |NULL            |NULL                     |NULL                                   |2023-02-23    |NULL                        |NULL                     |3704121732 |NULL       |NULL        |\n",
      "|UNIVERSIDAD 87|NULL       |ANTIOQUIA   |NULL  |NULL  |NULL                   |NULL            |NULL                     |NULL                                   |2023-11-13    |NULL                        |NULL                     |1993838284 |NULL       |NULL        |\n",
      "|INSTITUTO 61  |NULL       |CUNDINAMARCA|NULL  |NULL  |NULL                   |NULL            |NULL                     |NULL                                   |2023-09-30    |NULL                        |NULL                     |4437422507 |NULL       |NULL        |\n",
      "+--------------+-----------+------------+------+------+-----------------------+----------------+-------------------------+---------------------------------------+--------------+----------------------------+-------------------------+-----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bronze_path = \"file:/app/data/lakehouse/bronze/secop\"\n",
    "\n",
    "df_bronze_check = spark.read.format(\"delta\").load(bronze_path)\n",
    "print(\"Filas Bronze:\", df_bronze_check.count())\n",
    "df_bronze_check.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab84f9d-2ba6-40c0-961e-61a714d92656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
