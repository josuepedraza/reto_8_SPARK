{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74b4222-bd49-49f2-ab6e-afb05d481bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 2. Transformación (Capa Plata)\n",
    "# Limpieza, tipado fuerte y Quality Gate con bifurcación\n",
    "\n",
    "# %%\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, when, lit\n",
    "from delta import *\n",
    "\n",
    "# %%\n",
    "# Spark Session con Delta\n",
    "builder = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Lab_SECOP_Bronze\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.executor.memory\", \"1g\")\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27861ff7-bc8b-4b03-ae87-330695bb7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRONZE_PATH = \"file:/app/data/lakehouse/bronze/secop\"\n",
    "SILVER_PATH = \"file:/app/data/lakehouse/silver/secop\"\n",
    "QUAR_PATH   = \"file:/app/data/lakehouse/quarantine/secop_errors\"\n",
    "\n",
    "# Leer bronze\n",
    "df_bronze = spark.read.format(\"delta\").load(BRONZE_PATH)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Tipado de fecha (en Bronze la columna es: fecha_de_firma)\n",
    "df_typed = (\n",
    "    df_bronze\n",
    "    .withColumn(\"fecha_firma\", to_date(col(\"fecha_de_firma\"), \"yyyy-MM-dd\"))\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Definición de reglas de calidad y motivo de rechazo\n",
    "df_qc = df_typed.withColumn(\n",
    "    \"motivo_rechazo\",\n",
    "    when(col(\"precio_base\").isNull(), lit(\"precio_base_nulo\"))\n",
    "    .when(col(\"precio_base\") <= 0, lit(\"precio_base_no_positivo\"))\n",
    "    .when(col(\"fecha_firma\").isNull(), lit(\"fecha_firma_nula\"))\n",
    "    .otherwise(lit(None))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3db3a6bd-6282-4792-896b-aee55186f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Capa Silver generada: 1000 registros\n",
      "⚠️ Registros en Quarantine: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/02 02:18:43 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "26/02/02 02:18:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.errors.SparkCoreErrors$.clusterSchedulerError(SparkCoreErrors.scala:291)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:981)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:165)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:263)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:170)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n"
     ]
    }
   ],
   "source": [
    "# Split de datos\n",
    "df_validos = df_qc.filter(col(\"motivo_rechazo\").isNull())\n",
    "df_invalidos = df_qc.filter(col(\"motivo_rechazo\").isNotNull())\n",
    "\n",
    "# %%\n",
    "# Escribir capa Silver (solo registros válidos)\n",
    "(df_validos.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .save(SILVER_PATH)\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Escribir capa Quarantine (registros inválidos con motivo)\n",
    "(df_invalidos.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .save(QUAR_PATH)\n",
    ")\n",
    "# %%\n",
    "print(\"✅ Capa Silver generada:\", df_validos.count(), \"registros\")\n",
    "print(\"⚠️ Registros en Quarantine:\", df_invalidos.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05573e3-756f-4223-a82d-3d51e2f8bf90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
